{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc40c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "# flask\n",
    "import base64\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16972300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import import_ipynb\n",
    "import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b4da989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(Utils)\n",
    "from Utils import view_model, normal, renormal, load_model, dixon_q_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c032216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from models.ipynb\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request\n",
    "from flask import render_template, redirect, url_for\n",
    "app = Flask(__name__)\n",
    "\n",
    "import models\n",
    "from models import CNN, LSTM, GRU, RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b883d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://192.168.0.124:5000/ (Press CTRL+C to quit)\n",
      "192.168.0.11 - - [13/May/2023 00:27:20] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:27:21] \"GET /map HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:27:27] \"POST / HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:27:27] \"GET /map HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:27:32] \"POST /predict2 HTTP/1.1\" 200 -\n",
      "[2023-05-13 00:27:41,661] ERROR in app: Exception on /predict2 [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coinyawong/anaconda3/lib/python3.9/site-packages/flask/app.py\", line 2070, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/coinyawong/anaconda3/lib/python3.9/site-packages/flask/app.py\", line 1515, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/coinyawong/anaconda3/lib/python3.9/site-packages/flask/app.py\", line 1513, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/coinyawong/anaconda3/lib/python3.9/site-packages/flask/app.py\", line 1499, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"/tmp/ipykernel_16396/1553108811.py\", line 296, in predict2\n",
      "    model = load_model(o_path+'water'+str(w_id+1)+'/', str(period)+'_'+ft)\n",
      "  File \"<string>\", line 3, in load_model\n",
      "  File \"/home/coinyawong/anaconda3/lib/python3.9/site-packages/torch/serialization.py\", line 594, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/home/coinyawong/anaconda3/lib/python3.9/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/home/coinyawong/anaconda3/lib/python3.9/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './fail_model/water2/1_tp.pt'\n",
      "192.168.0.11 - - [13/May/2023 00:27:41] \"POST /predict2 HTTP/1.1\" 500 -\n",
      "[2023-05-13 00:27:48,270] ERROR in app: Exception on /predict [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coinyawong/anaconda3/lib/python3.9/site-packages/flask/app.py\", line 2070, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/coinyawong/anaconda3/lib/python3.9/site-packages/flask/app.py\", line 1515, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/coinyawong/anaconda3/lib/python3.9/site-packages/flask/app.py\", line 1513, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/coinyawong/anaconda3/lib/python3.9/site-packages/flask/app.py\", line 1499, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"/tmp/ipykernel_16396/1553108811.py\", line 122, in predict1\n",
      "    model = load_model(o_path+'water'+str(w_id+1)+'/', str(period)+'_'+ft)\n",
      "  File \"<string>\", line 3, in load_model\n",
      "  File \"/home/coinyawong/anaconda3/lib/python3.9/site-packages/torch/serialization.py\", line 594, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/home/coinyawong/anaconda3/lib/python3.9/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/home/coinyawong/anaconda3/lib/python3.9/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './fail_model/water2/1_tp.pt'\n",
      "192.168.0.11 - - [13/May/2023 00:27:48] \"POST /predict HTTP/1.1\" 500 -\n",
      "192.168.0.11 - - [13/May/2023 00:29:27] \"POST /predict HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:29:33] \"POST /predict2 HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:29:42] \"POST /predict2 HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:29:50] \"POST /predict2 HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:30:00] \"POST / HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:30:00] \"GET /map HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:30:08] \"POST /predict2 HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:30:14] \"POST /predict2 HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:30:21] \"POST /predict2 HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:30:25] \"POST /predict2 HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:32:06] \"POST / HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:32:06] \"GET /map HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:32:11] \"POST /predict2 HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:32:24] \"POST /predict2 HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:32:32] \"POST /predict2 HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:32:39] \"POST /predict2 HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:32:49] \"POST /predict2 HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:32:58] \"POST / HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:32:59] \"GET /map HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:33:04] \"POST /predict2 HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:33:12] \"POST /predict HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:33:36] \"POST / HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:33:36] \"GET /map HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:35:21] \"POST / HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:35:21] \"GET /map HTTP/1.1\" 200 -\n",
      "192.168.0.11 - - [13/May/2023 00:35:27] \"POST /predict2 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def hello():\n",
    "    if request.method == 'POST':\n",
    "        w_id = request.form.get('id')\n",
    "        period = request.form.get('period')\n",
    "        op = request.form.get('op')\n",
    "        \n",
    "        if not w_id or not period:\n",
    "            return render_template(\"layout.html\")\n",
    "\n",
    "        w_id = int(w_id)  # w_id를 정수형으로 변환\n",
    "        \n",
    "        if op == '0':\n",
    "            if w_id == 0:\n",
    "                df = pd.read_csv('./csv/han.csv')\n",
    "            elif w_id == 1:\n",
    "                df = pd.read_csv('./csv/gum.csv')\n",
    "            elif w_id == 2:\n",
    "                df = pd.read_csv('./csv/nak.csv')\n",
    "            elif w_id == 3:\n",
    "                df = pd.read_csv('./csv/yong.csv')\n",
    "        elif op == '1': # not satisfiy\n",
    "            if w_id == 0:\n",
    "                df = pd.read_csv('./csv/han_f.csv')\n",
    "            elif w_id == 1:\n",
    "                df = pd.read_csv('./csv/gum_f.csv')\n",
    "            elif w_id == 2:\n",
    "                df = pd.read_csv('./csv/nak_f.csv')\n",
    "            elif w_id == 3:\n",
    "                df = pd.read_csv('./csv/yong_f.csv')\n",
    "        else:\n",
    "            return render_template(\"layout.html\")\n",
    "\n",
    "        df = df[df['day'] == int(period)]\n",
    "        \n",
    "        templateData = {'col' : df['col'], 'day' : str(period), 'id': str(w_id), 'op': op}\n",
    "\n",
    "        return render_template(\"layout.html\", **templateData)\n",
    "    else:\n",
    "        return render_template(\"layout.html\")\n",
    "\n",
    "@app.route('/map')\n",
    "def mapping():\n",
    "    return render_template(\"map.html\")\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict1():\n",
    "    w_id = request.form.get('id')\n",
    "    period = request.form.get('period')\n",
    "    ft = request.form.get('ft')\n",
    "    op = request.form.get('op')\n",
    "    t_set = request.form.get('t_set')\n",
    "    \n",
    "    w_id = int(w_id)\n",
    "    period = int(period)\n",
    "    \n",
    "    # 모델 view\n",
    "    Data = pd.read_csv('./testset/origin/g_linear_amos_rtwqi'+str(w_id)+'.csv')[365*4*24:]\n",
    "    Data['m_date'] = pd.to_datetime(Data['m_date'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    Data['d2'] = Data['m_date'].dt.strftime('%Y-%m-%d')\n",
    "    w_list = [['temp', 'ph', 'ec', 'do', 'M73', 'toc', 'clola-a', 'ss', 'tn', 'flow_rate', \n",
    "               'tp', 'cod', 'a_water_depth', 'a_humidity', 'a_hpa', 'a_whpa', 'a_snow', \n",
    "               'a_dew_point', 'rtwqi', 'd2'], \n",
    "              ['temp', 'ph', 'ec', 'do', 'M73', 'toc', 'tn', 'tp', 'clola-a', 'a_water_depth',\n",
    "                'a_humidity', 'a_hpa', 'a_whpa', 'a_snow', 'a_dew_point', 'rtwqi', 'd2'],\n",
    "              ['temp', 'ph', 'ec', 'do', 'toc', 'tn', 'tp', 'clola-a', 'a_water_depth',\n",
    "                'a_humidity', 'a_hpa', 'a_whpa', 'a_snow', 'a_dew_point', 'rtwqi', 'd2'], \n",
    "              ['temp', 'ph', 'ec', 'do', 'M73', 'toc', 'tn', 'tp', 'clola-a', 'w_depth', 'a_water_depth',\n",
    "                'a_humidity', 'a_hpa', 'a_whpa', 'a_snow', 'a_dew_point','rtwqi', 'd2']]\n",
    "    #일별 예측이 목표이므로, 일별 평균으로 변환한다.    \n",
    "    Data2 = Data[w_list[w_id]].groupby('d2').mean()\n",
    "    Data2 = Data2.reset_index()\n",
    "    Data_n = pd.DataFrame(normal(Data2[Data2.columns[1:]]), columns = Data2.columns[1:])\n",
    "    \n",
    "    # 데이터 슬라이싱\n",
    "    days = period\n",
    "    if days == 1:\n",
    "        window_size = 5 # 5일치 데이터로 학습\n",
    "    elif days == 5:\n",
    "        window_size = 20\n",
    "    elif days == 7:\n",
    "        window_size = 14\n",
    "    elif days == 14:\n",
    "        window_size = 28\n",
    "\n",
    "    # 1.1~1.5일 train / 1.6 test부터 시작\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(len(Data_n)-window_size-days):\n",
    "        X.append(Data_n[i:i+window_size])\n",
    "        Y.append(Data_n[i+window_size:i+window_size+days][ft])\n",
    "    X2 = np.array(X)\n",
    "    Y2 = np.array(Y)\n",
    "    X2 = torch.tensor(X2, dtype=torch.float32)\n",
    "    Y2 = torch.tensor(Y2, dtype=torch.float32)\n",
    "    \n",
    "    o_path = './best_model/'\n",
    "    \n",
    "    if op == '0':\n",
    "        if w_id == 0:\n",
    "            df = pd.read_csv('./csv/han.csv')\n",
    "        elif w_id == 1:\n",
    "            df = pd.read_csv('./csv/gum.csv')\n",
    "        elif w_id == 2:\n",
    "            df = pd.read_csv('./csv/nak.csv')\n",
    "        elif w_id == 3:\n",
    "            df = pd.read_csv('./csv/yong.csv')\n",
    "    elif op == '1': # not satisfiy\n",
    "        o_path = './fail_model/'\n",
    "        if w_id == 0:\n",
    "            df = pd.read_csv('./csv/han_f.csv')\n",
    "        elif w_id == 1:\n",
    "            df = pd.read_csv('./csv/gum_f.csv')\n",
    "        elif w_id == 2:\n",
    "            df = pd.read_csv('./csv/nak_f.csv')\n",
    "        elif w_id == 3:\n",
    "            df = pd.read_csv('./csv/yong_f.csv')\n",
    "        \n",
    "    # 모델종류    \n",
    "    md = df[(df['day'] == period) & (df['col'] == ft)]['model'].values[0]\n",
    "    \n",
    "    model = load_model(o_path+'water'+str(w_id+1)+'/', str(period)+'_'+ft)\n",
    "    \n",
    "    #view\n",
    "    loss_fn = nn.MSELoss()\n",
    "    if md == 'c':\n",
    "        output = model(X2)\n",
    "    else:\n",
    "        output = model(X2, days)\n",
    "    nse = 1. - torch.sum(torch.square(Y2-output))/torch.sum(torch.square(Y2-torch.mean(Y2)))\n",
    "    mse = mean_squared_error(Y2.cpu().detach().numpy(), output.cpu().detach().numpy())\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "    t1 = output.cpu().detach().numpy()\n",
    "    t2 = Y2.cpu().detach().numpy()\n",
    "\n",
    "    show_predict = pd.DataFrame({'y': t2[0].reshape(-1), 'pred': t1[0].reshape(-1)})\n",
    "    for i in range(1, len(t1)):\n",
    "        nw = {'y': t2[i][-1], 'pred': t1[i][-1]}\n",
    "        show_predict = show_predict.append(nw, ignore_index=True)\n",
    "\n",
    "    show_predict = renormal(show_predict, [Data2[ft].min(), Data2[ft].max()])\n",
    "    show_predict['d2'] = Data2['d2'][window_size:-1].values\n",
    "\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.title('prediction graph:'+ft)\n",
    "    plt.plot(show_predict['y'], label='origin')\n",
    "    plt.plot(show_predict['pred'], label='predict')\n",
    "    plt.legend()\n",
    "    \n",
    "    #plt save\n",
    "    buffer = io.BytesIO()\n",
    "    plt.savefig(buffer, format='png')\n",
    "    buffer.seek(0)\n",
    "    plot_data = base64.b64encode(buffer.read()).decode()\n",
    "    \n",
    "    templateData = {'data': show_predict[:period], 'col' : ft, 'day' : str(period), 'id': str(w_id), 'md': md, 'loss': round(loss_fn(output, Y2).item(), 2), 'rmse': round(rmse, 2), 'nse': round(nse.item(), 2), 'plot_data': plot_data, 't_set': t_set}\n",
    "    \n",
    "    return render_template(\"predict.html\",  **templateData)\n",
    "\n",
    "#2023. 3월 데이터로 예측\n",
    "@app.route('/predict2', methods=['POST'])\n",
    "def predict2():\n",
    "    w_id = request.form.get('id')\n",
    "    period = request.form.get('period')\n",
    "    ft = request.form.get('ft')\n",
    "    op = request.form.get('op')\n",
    "    t_set = request.form.get('t_set')\n",
    "    \n",
    "    w_id = int(w_id)\n",
    "    period = int(period)\n",
    "    \n",
    "    w_list = [['temp', 'ph', 'ec', 'do', 'M73', 'toc', 'clola-a', 'ss', 'tn', 'flow_rate', \n",
    "               'tp', 'cod', 'a_water_depth', 'a_humidity', 'a_hpa', 'a_whpa', 'a_snow', \n",
    "               'a_dew_point', 'rtwqi', 'd2'], \n",
    "              ['temp', 'ph', 'ec', 'do', 'M73', 'toc', 'tn', 'tp', 'clola-a', 'a_water_depth',\n",
    "                'a_humidity', 'a_hpa', 'a_whpa', 'a_snow', 'a_dew_point', 'rtwqi', 'd2'],\n",
    "              ['temp', 'ph', 'ec', 'do', 'toc', 'tn', 'tp', 'clola-a', 'a_water_depth',\n",
    "                'a_humidity', 'a_hpa', 'a_whpa', 'a_snow', 'a_dew_point', 'rtwqi', 'd2'], \n",
    "              ['temp', 'ph', 'ec', 'do', 'M73', 'toc', 'tn', 'tp', 'clola-a', 'w_depth', 'a_water_depth',\n",
    "                'a_humidity', 'a_hpa', 'a_whpa', 'a_snow', 'a_dew_point','rtwqi', 'd2']]\n",
    "\n",
    "    # 데이터 가공\n",
    "    t1 = pd.read_csv('./testset/new/auto_water'+str(w_id)+'.csv')[:30*24]\n",
    "    t2 = pd.read_csv('./testset/new/asos_water'+str(w_id)+'.csv', encoding='cp949')\n",
    "    t4 = pd.read_csv('./testset/new/m_water'+str(w_id)+'.csv', encoding='cp949')\n",
    "    \n",
    "    #수질측정망 가공\n",
    "    t4 = t4[['년/월/일', 'SS(㎎/L)', 'TN(㎎/L)', '유량(㎥/s)', '수심(m)', 'TP(㎎/L)', 'COD(㎎/L)']]\n",
    "    t4.columns = ['m_date', 'ss', 'tn', 'flow_rate', 'w_depth', 'tp', 'cod']\n",
    "    t4['m_date'] = pd.to_datetime(t4['m_date'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    \n",
    "    # 수계에 따른 feature get\n",
    "    if w_id == 0:\n",
    "        f = w_list[w_id][:7]\n",
    "        t4 = t4[['m_date', 'ss', 'tn', 'flow_rate', 'tp', 'cod']]\n",
    "    elif w_id == 1:\n",
    "        f = w_list[w_id][:9]\n",
    "        t1['tp'].replace('ND', 0, inplace=True)\n",
    "        t1['tp'] = t1['tp'].astype(float)\n",
    "    elif w_id == 2:  \n",
    "        f = w_list[w_id][:8]\n",
    "        t1['tp'].replace('ND', 0, inplace=True)\n",
    "        t1['tp'] = t1['tp'].astype(float)\n",
    "    elif w_id == 3:\n",
    "        f = w_list[w_id][:9]\n",
    "        t1['tp'].replace('ND', 0, inplace=True)\n",
    "        t1['tp'] = t1['tp'].astype(float)\n",
    "        t4 = t4[['m_date', 'w_depth']]\n",
    "    f.append('m_date')\n",
    "    f.append('rtwqi')\n",
    "    f.append('g_rtwqi')\n",
    "\n",
    "    t1 = t1[f]\n",
    "\n",
    "    # 여기서 q-test로 이상치처리 데이터 학습을 시도\n",
    "    t3 = t1.copy() # 원본데이터 저장 #\n",
    "    t1 = t1.interpolate()\n",
    "    t1 = dixon_q_test(t1) #이상치 처리\n",
    "    t1 = t1.interpolate()\n",
    "    t1['m_date'] = t1['m_date'].str.replace('h', ':00', 1)\n",
    "    t1['m_date'] = pd.to_datetime(t1['m_date'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    t3['m_date'] = t3['m_date'].str.replace('h', ':00', 1) #\n",
    "    t3['m_date'] = pd.to_datetime(t3['m_date'], format='%Y-%m-%d %H:%M', errors='raise') #\n",
    "    t2 = t2[['일시', '강수량(mm)', '습도(%)', '현지기압(hPa)', '해면기압(hPa)', '적설(cm)', '이슬점온도(°C)']]\n",
    "    t2.columns = ['m_date', 'a_water_depth', 'a_humidity', 'a_hpa', 'a_whpa', 'a_snow', 'a_dew_point']\n",
    "    t2[['a_water_depth', 'a_snow']] = t2[['a_water_depth', 'a_snow']].fillna(0)\n",
    "    t2 = t2.interpolate()\n",
    "    t2['m_date'] = pd.to_datetime(t2['m_date'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    \n",
    "    Data = pd.merge(t1, t2, on='m_date', how='inner')\n",
    "    if w_id in [0, 3]:\n",
    "        Data = pd.merge(Data, t4, how='left', on='m_date')\n",
    "        Data[Data.columns[-5:]] = Data[Data.columns[-5:]].interpolate()\n",
    "        Data[Data.columns[-5:]] = Data[Data.columns[-5:]].interpolate(method='bfill')\n",
    "    \n",
    "    Data['d2'] = Data['m_date'].dt.strftime('%Y-%m-%d')\n",
    "    Data2 = Data[w_list[w_id]].groupby('d2').mean()\n",
    "    Data2 = Data2.reset_index()\n",
    "    Data_n = pd.DataFrame(normal(Data2[Data2.columns[1:]]), columns = Data2.columns[1:])\n",
    "\n",
    "    #t3 처리\n",
    "    t3['d2'] = t3['m_date'].dt.strftime('%Y-%m-%d')\n",
    "    t3 = t3.groupby('d2').mean()\n",
    "    t3 = t3.reset_index()\n",
    "\n",
    "    # 데이터 슬라이싱\n",
    "    days = period\n",
    "    if days == 1:\n",
    "        window_size = 5 # 5일치 데이터로 학습\n",
    "    elif days == 5:\n",
    "        window_size = 20\n",
    "    elif days == 7:\n",
    "        window_size = 14\n",
    "    elif days == 14:\n",
    "        window_size = 28\n",
    "\n",
    "    # 1.1~1.5일 train / 1.6 test부터 시작\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(len(Data_n)-window_size-days):\n",
    "        X.append(Data_n[i:i+window_size])\n",
    "        Y.append(Data_n[i+window_size:i+window_size+days][ft])\n",
    "    X2 = np.array(X)\n",
    "    Y2 = np.array(Y)\n",
    "    X2 = torch.tensor(X2, device=\"cpu\", dtype=torch.float32)\n",
    "    Y2 = torch.tensor(Y2, device=\"cpu\", dtype=torch.float32)\n",
    "    \n",
    "    o_path = './best_model/'\n",
    "    \n",
    "    if op == '0':\n",
    "        if w_id == 0:\n",
    "            df = pd.read_csv('./csv/han.csv')\n",
    "        elif w_id == 1:\n",
    "            df = pd.read_csv('./csv/gum.csv')\n",
    "        elif w_id == 2:\n",
    "            df = pd.read_csv('./csv/nak.csv')\n",
    "        elif w_id == 3:\n",
    "            df = pd.read_csv('./csv/yong.csv')\n",
    "    elif op == '1': # not satisfiy\n",
    "        o_path = './fail_model/'\n",
    "        if w_id == 0:\n",
    "            df = pd.read_csv('./csv/han_f.csv')\n",
    "        elif w_id == 1:\n",
    "            df = pd.read_csv('./csv/gum_f.csv')\n",
    "        elif w_id == 2:\n",
    "            df = pd.read_csv('./csv/nak_f.csv')\n",
    "        elif w_id == 3:\n",
    "            df = pd.read_csv('./csv/yong_f.csv')\n",
    "\n",
    "\n",
    "    # 모델종류    \n",
    "    md = df[(df['day'] == period) & (df['col'] == ft)]['model'].values[0]\n",
    "    \n",
    "    model = load_model(o_path+'water'+str(w_id+1)+'/', str(period)+'_'+ft)\n",
    "    \n",
    "    #view\n",
    "    loss_fn = nn.MSELoss()\n",
    "    if md == 'c':\n",
    "        output = model(X2)\n",
    "    else:\n",
    "        output = model(X2, days)\n",
    "    nse = 1. - torch.sum(torch.square(Y2-output))/torch.sum(torch.square(Y2-torch.mean(Y2)))\n",
    "    mse = mean_squared_error(Y2.cpu().detach().numpy(), output.cpu().detach().numpy())\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    t1 = output.cpu().detach().numpy()\n",
    "    t2 = Y2.cpu().detach().numpy()\n",
    "\n",
    "    show_predict = pd.DataFrame({'y': t2[0].reshape(-1), 'pred': t1[0].reshape(-1)})\n",
    "    for i in range(1, len(t1)):\n",
    "        nw = {'y': t2[i][-1], 'pred': t1[i][-1]}\n",
    "        show_predict = show_predict.append(nw, ignore_index=True)\n",
    "\n",
    "    show_predict = renormal(show_predict, [Data2[ft].min(), Data2[ft].max()])\n",
    "    if ft in f:\n",
    "        show_predict['origin'] = t3.iloc[window_size:-1][ft].values\n",
    "    show_predict['d2'] = Data2['d2'][window_size:-1].values\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.title('prediction graph:'+ft)\n",
    "    if ft in f:\n",
    "        plt.plot(show_predict['origin'], label='origin')\n",
    "    plt.plot(show_predict['y'], label='q_test_origin')\n",
    "    plt.plot(show_predict['pred'], label='predict')\n",
    "    plt.legend()\n",
    "    \n",
    "    #plt save\n",
    "    buffer = io.BytesIO()\n",
    "    plt.savefig(buffer, format='png')\n",
    "    buffer.seek(0)\n",
    "    plot_data = base64.b64encode(buffer.read()).decode()\n",
    "    \n",
    "    \n",
    "    templateData = {'data': show_predict[:period], 'col' : ft, 'day' : str(period), 'id': str(w_id), 'md': md, 'loss': round(loss_fn(output, Y2).item(), 2), 'rmse': round(rmse, 2), 'nse': round(nse.item(), 2), 'plot_data': plot_data, 't_set': t_set}\n",
    "    \n",
    "    return render_template(\"predict.html\",  **templateData)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78ea95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
